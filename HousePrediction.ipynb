{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# House Price Prediction\n",
    "\n",
    "- [1 - Introduction](#Introduction)\n",
    "    - [1.1 - Project Overview](#Project-Overview)\n",
    "    - [1.2 - Problem Statement](#Problem-Statement)\n",
    "    - [1.3 - Dataset Description](#Dataset-Description)\n",
    "\n",
    "- [2 - Import Libraries](#Import-Libraries)\n",
    "\n",
    "- [3 - Data Loading and Exploration](#Data-Loading-and-Exploration)\n",
    "    - [3.1 - Load the Dataset](#Load-the-Dataset)\n",
    "    - [3.2 - Display Basic Information](#Display-Basic-Information)\n",
    "    \n",
    "- [4 - Data Preprocessing](#Data-Preprocessing)\n",
    "    - [4.1 - Removing irrelevant Features](#Removing-irrelevant-Features)\n",
    "    - [4.2 - Handle Missing Values](#Handle-Missing-Values)\n",
    "    - [4.3 - Encode Categorical Variables](#Encode-Categorical-Variables)\n",
    "    - [4.4 - Feature Scaling](#Feature-Scaling)\n",
    "\n",
    "- [5 - Data Splitting](#Data-Splitting)\n",
    "    - [5.1 - Split into Train, Validation, and Test Sets](#Split-into-Train-Validation-and-Test-Sets)\n",
    "    - [5.2 - Split Data into Features (X) and Target (y)](#Split-Data-into-Features-X-and-Target-y)\n",
    "\n",
    "\n",
    "- [6 - Model Definition and Training](#Model-Definition)\n",
    "    - [6.1 - Define the Logistic Regression Model using Sklearn](#Define-the-Logistic-Regression-Model-using-Sklearn)\n",
    "    - [6.2 - Train the Model](#Train-the-Model)\n",
    "    - [6.3 - Evaluating Model on Validation Set](#Validation-During-Training)\n",
    "\n",
    "- [7 - Hypertuning of Model](#Hypertuning-of-Model)\n",
    "\n",
    "- [8 - Model Evaluation](#Model-Evaluation)\n",
    "    - [8.1 - Confusion Matrix and Scores](#Confusion-Matrix-and-Scores)\n",
    "    - [8.2 - ROC Curve](#ROC-Curve)\n",
    "\n",
    "- [9 - Conclusion](#Conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Introduction\n",
    "\n",
    "## 1.1 - Project Overview\n",
    "The goal of this project is to develop a predictive model that can estimate the prices of houses in Bengaluru, India. Accurately predicting house prices is crucial for real estate agents, buyers, and sellers to make informed decisions. By analyzing various factors such as the size of the property, location, and available amenities, we aim to build a machine learning model that can effectively predict house prices based on historical data.\n",
    "\n",
    "## 1.2 - Problem Statement\n",
    "The real estate market in Bengaluru is dynamic and influenced by multiple factors, making it challenging to estimate property prices accurately. The primary objective of this project is to address the following questions:\n",
    "\n",
    "- Can we build an accurate model to predict house prices using historical real estate data from Bengaluru?\n",
    "- How can we interpret the model's predictions to provide actionable insights for real estate professionals and potential buyers?\n",
    "\n",
    "By answering these questions, we aim to create a tool that can assist in making more accurate and informed real estate decisions.\n",
    "\n",
    "## 1.3 - Dataset Description\n",
    "The dataset used in this project is sourced from Kaggle and contains detailed information on various properties in Bengaluru, India.\n",
    "\n",
    "### Bengaluru House Data\n",
    "Each row in the dataset represents a property listing, and each column provides different attributes about the properties.\n",
    "\n",
    "- **Number of Rows:** 13,320 (properties)\n",
    "- **Number of Columns:** 9 (features)\n",
    "- **Target Column:** \"price\"\n",
    "\n",
    "### Data Composition\n",
    "The dataset includes the following information:\n",
    "\n",
    "- **Area Type:**\n",
    "  - The type of area (e.g., Super built-up Area, Plot Area, Built-up Area).\n",
    "\n",
    "- **Availability:**\n",
    "  - The availability status of the property (e.g., Ready to Move, available from a specific date).\n",
    "\n",
    "- **Location:**\n",
    "  - The location of the property within Bengaluru.\n",
    "\n",
    "- **Size:**\n",
    "  - The size of the property in terms of the number of bedrooms (e.g., 2 BHK, 3 Bedroom).\n",
    "\n",
    "- **Total Area:**\n",
    "  - The total area of the property in square feet.\n",
    "\n",
    "- **Number of Bathrooms:**\n",
    "  - The number of bathrooms available in the property.\n",
    "\n",
    "- **Number of Balconies:**\n",
    "  - The number of balconies available in the property.\n",
    "\n",
    "This dataset provides a comprehensive view of the real estate market in Bengaluru, allowing us to analyze and model the factors that influence house prices effectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [2 - Import Libraries](#Import-Libraries)\n",
    "\n",
    "In this section, we import the necessary libraries required for data manipulation, visualization, and building a machine learning model using Sklearn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic libraries for data manipulation and visualization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sklearn for data preprocessing, building, training the model and evaluation\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [3 - Data Loading and Exploration](#Data-Loading-and-Exploration)\n",
    "\n",
    "## [3.1 - Load the Dataset](#Load-the-Dataset)\n",
    "\n",
    "In this section, we will load the Bengaluru House dataset into a pandas DataFrame for further exploration and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset into a pandas DataFrame\n",
    "data_path = './Bengaluru_House_Data.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Display the first few rows of the dataset to verify loading\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [3.2 - Display Basic Information](#Display-Basic-Information)\n",
    "\n",
    "In this section, we will display basic information about the dataset to understand its structure and contents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the basic information about the dataset\n",
    "df.info()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [4 - Data Preprocessing](#Data-Preprocessing)\n",
    "\n",
    "## [4.1 - Removing irrelevant Features](#Removing-irrelevant-Features)\n",
    "\n",
    "In this section we will remove irrelevant features which we assume do not have any decisive weight for the target (house price)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will remove the 'availability' feature from the dataframe, as it is considered irrelevant for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove irrelevant features from the dataframe\n",
    "df.drop(['availability'], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [4.2 - Handle Missing Values](#Handle-Missing-Values)\n",
    "\n",
    "In this section, we will identify and handle missing values in the dataset to ensure the data is clean and ready for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = df.isnull().sum()\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5502 out of 13320 Samples do not have a value for **society**, therefore we will drop society too as feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['society'], axis=1)\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
